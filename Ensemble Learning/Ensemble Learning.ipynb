{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(solver=\"liblinear\")\n",
    "svm = SVC(gamma=\"auto\")\n",
    "random_forest = RandomForestClassifier(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "                            estimators = [('lr', log_reg), ('rf', random_forest), ('svc', svm)],\n",
    "                            voting = \"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='liblinear', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='g...\n",
       "                                                     n_jobs=None,\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=None,\n",
       "                                                     verbose=0,\n",
       "                                                     warm_start=False)),\n",
       "                             ('svc',\n",
       "                              SVC(C=1.0, cache_size=200, class_weight=None,\n",
       "                                  coef0=0.0, decision_function_shape='ovr',\n",
       "                                  degree=3, gamma='auto', kernel='rbf',\n",
       "                                  max_iter=-1, probability=False,\n",
       "                                  random_state=None, shrinking=True, tol=0.001,\n",
       "                                  verbose=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "SVC 0.888\n",
      "RandomForestClassifier 0.904\n",
      "VotingClassifier 0.896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_reg, svm, random_forest, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(solver=\"liblinear\")\n",
    "svm = SVC(gamma=\"auto\", probability = True)\n",
    "random_forest = RandomForestClassifier(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "                            estimators = [('lr', log_reg), ('rf', random_forest), ('svc', svm)],\n",
    "                            voting = \"soft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                        criterion='gini',\n",
       "                                                        max_depth=None,\n",
       "                                                        max_features=None,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=1,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        presort=False,\n",
       "                                                        random_state=None,\n",
       "                                                        splitter='best'),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                  max_samples=100, n_estimators=500, n_jobs=-1, oob_score=True,\n",
       "                  random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "                            DecisionTreeClassifier(), n_estimators = 500,\n",
    "                            max_samples = 100, bootstrap = True, n_jobs = -1, oob_score = True)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9253333333333333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36507937, 0.63492063],\n",
       "       [0.38147139, 0.61852861],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00515464, 0.99484536],\n",
       "       [0.01282051, 0.98717949],\n",
       "       [0.09973753, 0.90026247],\n",
       "       [0.40203562, 0.59796438],\n",
       "       [0.08115183, 0.91884817],\n",
       "       [0.94579946, 0.05420054],\n",
       "       [0.83378016, 0.16621984],\n",
       "       [0.5890411 , 0.4109589 ],\n",
       "       [0.03367876, 0.96632124],\n",
       "       [0.72351421, 0.27648579],\n",
       "       [0.8537234 , 0.1462766 ],\n",
       "       [0.91269841, 0.08730159],\n",
       "       [0.10471204, 0.89528796],\n",
       "       [0.03282828, 0.96717172],\n",
       "       [0.92875318, 0.07124682],\n",
       "       [0.66149871, 0.33850129],\n",
       "       [0.94850949, 0.05149051],\n",
       "       [0.05292479, 0.94707521],\n",
       "       [0.2265625 , 0.7734375 ],\n",
       "       [0.90106952, 0.09893048],\n",
       "       [0.99234694, 0.00765306],\n",
       "       [0.96551724, 0.03448276],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95918367, 0.04081633],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02046036, 0.97953964],\n",
       "       [0.68298969, 0.31701031],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01030928, 0.98969072],\n",
       "       [0.07894737, 0.92105263],\n",
       "       [0.08376963, 0.91623037],\n",
       "       [0.96816976, 0.03183024],\n",
       "       [0.01058201, 0.98941799],\n",
       "       [0.58666667, 0.41333333],\n",
       "       [0.00512821, 0.99487179],\n",
       "       [0.98963731, 0.01036269],\n",
       "       [0.16020672, 0.83979328],\n",
       "       [0.35752688, 0.64247312],\n",
       "       [0.99741602, 0.00258398],\n",
       "       [0.99462366, 0.00537634],\n",
       "       [0.00542005, 0.99457995],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.04239401, 0.95760599],\n",
       "       [0.98740554, 0.01259446],\n",
       "       [0.03645833, 0.96354167],\n",
       "       [0.95561358, 0.04438642],\n",
       "       [0.82894737, 0.17105263],\n",
       "       [0.91731266, 0.08268734],\n",
       "       [0.8172043 , 0.1827957 ],\n",
       "       [0.01538462, 0.98461538],\n",
       "       [0.08527132, 0.91472868],\n",
       "       [0.81912145, 0.18087855],\n",
       "       [0.02917772, 0.97082228],\n",
       "       [0.01044386, 0.98955614],\n",
       "       [0.06005222, 0.93994778],\n",
       "       [0.85111663, 0.14888337],\n",
       "       [0.62140992, 0.37859008],\n",
       "       [0.72236504, 0.27763496],\n",
       "       [0.98717949, 0.01282051],\n",
       "       [0.02025316, 0.97974684],\n",
       "       [0.7983871 , 0.2016129 ],\n",
       "       [0.98955614, 0.01044386],\n",
       "       [0.98421053, 0.01578947],\n",
       "       [0.6109589 , 0.3890411 ],\n",
       "       [0.98087432, 0.01912568],\n",
       "       [0.32207792, 0.67792208],\n",
       "       [0.32405063, 0.67594937],\n",
       "       [0.41147132, 0.58852868],\n",
       "       [0.65736041, 0.34263959],\n",
       "       [0.00510204, 0.99489796],\n",
       "       [0.33153639, 0.66846361],\n",
       "       [0.90306122, 0.09693878],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03084833, 0.96915167],\n",
       "       [0.96226415, 0.03773585],\n",
       "       [0.00810811, 0.99189189],\n",
       "       [0.20316623, 0.79683377],\n",
       "       [0.13573407, 0.86426593],\n",
       "       [0.42276423, 0.57723577],\n",
       "       [0.98108108, 0.01891892],\n",
       "       [0.04644809, 0.95355191],\n",
       "       [0.58536585, 0.41463415],\n",
       "       [0.04438642, 0.95561358],\n",
       "       [0.03674541, 0.96325459],\n",
       "       [0.00518135, 0.99481865],\n",
       "       [0.38931298, 0.61068702],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00815217, 0.99184783],\n",
       "       [0.05026455, 0.94973545],\n",
       "       [0.00257732, 0.99742268],\n",
       "       [0.79210526, 0.20789474],\n",
       "       [0.68503937, 0.31496063],\n",
       "       [0.05405405, 0.94594595],\n",
       "       [0.9974026 , 0.0025974 ],\n",
       "       [0.31538462, 0.68461538],\n",
       "       [0.63846154, 0.36153846],\n",
       "       [0.00255102, 0.99744898],\n",
       "       [0.08776596, 0.91223404],\n",
       "       [0.45408163, 0.54591837],\n",
       "       [0.97461929, 0.02538071],\n",
       "       [0.0616622 , 0.9383378 ],\n",
       "       [0.98947368, 0.01052632],\n",
       "       [0.43908629, 0.56091371],\n",
       "       [0.26165803, 0.73834197],\n",
       "       [0.99206349, 0.00793651],\n",
       "       [0.23684211, 0.76315789],\n",
       "       [0.83896104, 0.16103896],\n",
       "       [0.25765306, 0.74234694],\n",
       "       [0.75989446, 0.24010554],\n",
       "       [0.98701299, 0.01298701],\n",
       "       [0.98181818, 0.01818182],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.4781491 , 0.5218509 ],\n",
       "       [0.99469496, 0.00530504],\n",
       "       [0.07425743, 0.92574257],\n",
       "       [0.98663102, 0.01336898],\n",
       "       [0.9762533 , 0.0237467 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.97002725, 0.02997275],\n",
       "       [0.04987531, 0.95012469],\n",
       "       [0.94285714, 0.05714286],\n",
       "       [0.95177665, 0.04822335],\n",
       "       [0.01866667, 0.98133333],\n",
       "       [0.2513089 , 0.7486911 ],\n",
       "       [0.88040712, 0.11959288],\n",
       "       [0.35714286, 0.64285714],\n",
       "       [0.90026247, 0.09973753],\n",
       "       [0.00271003, 0.99728997],\n",
       "       [0.03092784, 0.96907216],\n",
       "       [0.81818182, 0.18181818],\n",
       "       [0.75706215, 0.24293785],\n",
       "       [0.56847545, 0.43152455],\n",
       "       [0.8828125 , 0.1171875 ],\n",
       "       [0.93947368, 0.06052632],\n",
       "       [0.13089005, 0.86910995],\n",
       "       [0.82479784, 0.17520216],\n",
       "       [0.043257  , 0.956743  ],\n",
       "       [0.00775194, 0.99224806],\n",
       "       [0.13910761, 0.86089239],\n",
       "       [0.74309392, 0.25690608],\n",
       "       [0.97631579, 0.02368421],\n",
       "       [1.        , 0.        ],\n",
       "       [0.04851752, 0.95148248],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06666667, 0.93333333],\n",
       "       [0.03324808, 0.96675192],\n",
       "       [0.99744246, 0.00255754],\n",
       "       [0.97      , 0.03      ],\n",
       "       [0.8707124 , 0.1292876 ],\n",
       "       [0.99485861, 0.00514139],\n",
       "       [1.        , 0.        ],\n",
       "       [0.89717224, 0.10282776],\n",
       "       [0.        , 1.        ],\n",
       "       [0.68206522, 0.31793478],\n",
       "       [0.37371134, 0.62628866],\n",
       "       [0.08505155, 0.91494845],\n",
       "       [0.01550388, 0.98449612],\n",
       "       [0.41424802, 0.58575198],\n",
       "       [0.99261084, 0.00738916],\n",
       "       [0.976     , 0.024     ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98740554, 0.01259446],\n",
       "       [0.03989362, 0.96010638],\n",
       "       [0.        , 1.        ],\n",
       "       [0.94148936, 0.05851064],\n",
       "       [0.00759494, 0.99240506],\n",
       "       [0.00271003, 0.99728997],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03108808, 0.96891192],\n",
       "       [0.84455959, 0.15544041],\n",
       "       [0.92582418, 0.07417582],\n",
       "       [0.04071247, 0.95928753],\n",
       "       [0.94573643, 0.05426357],\n",
       "       [0.92307692, 0.07692308],\n",
       "       [0.95800525, 0.04199475],\n",
       "       [0.01075269, 0.98924731],\n",
       "       [0.01851852, 0.98148148],\n",
       "       [0.99487179, 0.00512821],\n",
       "       [0.235     , 0.765     ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.08928571, 0.91071429],\n",
       "       [0.02088773, 0.97911227],\n",
       "       [0.99186992, 0.00813008],\n",
       "       [0.        , 1.        ],\n",
       "       [0.1852861 , 0.8147139 ],\n",
       "       [0.91770574, 0.08229426],\n",
       "       [0.92857143, 0.07142857],\n",
       "       [0.63324538, 0.36675462],\n",
       "       [0.67700258, 0.32299742],\n",
       "       [0.02072539, 0.97927461],\n",
       "       [0.29367089, 0.70632911],\n",
       "       [0.97650131, 0.02349869],\n",
       "       [0.91959799, 0.08040201],\n",
       "       [0.91223404, 0.08776596],\n",
       "       [0.9816273 , 0.0183727 ],\n",
       "       [0.05626598, 0.94373402],\n",
       "       [0.00529101, 0.99470899],\n",
       "       [0.0835443 , 0.9164557 ],\n",
       "       [0.5112782 , 0.4887218 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02067183, 0.97932817],\n",
       "       [0.97650131, 0.02349869],\n",
       "       [0.09243697, 0.90756303],\n",
       "       [0.11311054, 0.88688946],\n",
       "       [0.90151515, 0.09848485],\n",
       "       [0.05764411, 0.94235589],\n",
       "       [0.37533512, 0.62466488],\n",
       "       [0.00522193, 0.99477807],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01078167, 0.98921833],\n",
       "       [0.01081081, 0.98918919],\n",
       "       [0.93139842, 0.06860158],\n",
       "       [0.90885417, 0.09114583],\n",
       "       [0.94974874, 0.05025126],\n",
       "       [0.01578947, 0.98421053],\n",
       "       [0.096     , 0.904     ],\n",
       "       [0.95212766, 0.04787234],\n",
       "       [0.16062176, 0.83937824],\n",
       "       [0.00258398, 0.99741602],\n",
       "       [0.27925532, 0.72074468],\n",
       "       [0.96923077, 0.03076923],\n",
       "       [0.84408602, 0.15591398],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.73854447, 0.26145553],\n",
       "       [0.92513369, 0.07486631],\n",
       "       [0.16089109, 0.83910891],\n",
       "       [0.1305483 , 0.8694517 ],\n",
       "       [0.99738903, 0.00261097],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01530612, 0.98469388],\n",
       "       [0.0078534 , 0.9921466 ],\n",
       "       [0.38974359, 0.61025641],\n",
       "       [0.87037037, 0.12962963],\n",
       "       [0.048     , 0.952     ],\n",
       "       [0.98924731, 0.01075269],\n",
       "       [0.87061995, 0.12938005],\n",
       "       [0.        , 1.        ],\n",
       "       [0.77333333, 0.22666667],\n",
       "       [0.98138298, 0.01861702],\n",
       "       [0.01570681, 0.98429319],\n",
       "       [0.99748111, 0.00251889],\n",
       "       [0.07086614, 0.92913386],\n",
       "       [0.00257732, 0.99742268],\n",
       "       [0.12113402, 0.87886598],\n",
       "       [0.25668449, 0.74331551],\n",
       "       [0.85224274, 0.14775726],\n",
       "       [0.06419753, 0.93580247],\n",
       "       [0.99462366, 0.00537634],\n",
       "       [0.68058968, 0.31941032],\n",
       "       [0.07588076, 0.92411924],\n",
       "       [0.66137566, 0.33862434],\n",
       "       [0.87760417, 0.12239583],\n",
       "       [0.01278772, 0.98721228],\n",
       "       [0.99480519, 0.00519481],\n",
       "       [0.02072539, 0.97927461],\n",
       "       [0.        , 1.        ],\n",
       "       [0.70744681, 0.29255319],\n",
       "       [0.        , 1.        ],\n",
       "       [0.9870801 , 0.0129199 ],\n",
       "       [0.15584416, 0.84415584],\n",
       "       [0.76358696, 0.23641304],\n",
       "       [0.10459184, 0.89540816],\n",
       "       [0.99220779, 0.00779221],\n",
       "       [0.86702128, 0.13297872],\n",
       "       [0.008     , 0.992     ],\n",
       "       [0.08877285, 0.91122715],\n",
       "       [0.13164557, 0.86835443],\n",
       "       [0.07631579, 0.92368421],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97979798, 0.02020202],\n",
       "       [0.86005089, 0.13994911],\n",
       "       [0.20472441, 0.79527559],\n",
       "       [0.91863517, 0.08136483],\n",
       "       [0.04909561, 0.95090439],\n",
       "       [0.61256545, 0.38743455],\n",
       "       [0.10714286, 0.89285714],\n",
       "       [0.96505376, 0.03494624],\n",
       "       [0.87399464, 0.12600536],\n",
       "       [0.00531915, 0.99468085],\n",
       "       [0.94680851, 0.05319149],\n",
       "       [0.88265306, 0.11734694],\n",
       "       [0.00259067, 0.99740933],\n",
       "       [0.05329949, 0.94670051],\n",
       "       [0.99751861, 0.00248139],\n",
       "       [0.032     , 0.968     ],\n",
       "       [0.99470899, 0.00529101],\n",
       "       [0.06940874, 0.93059126],\n",
       "       [0.90180879, 0.09819121],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00518135, 0.99481865],\n",
       "       [0.02337662, 0.97662338],\n",
       "       [0.72      , 0.28      ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.68523002, 0.31476998],\n",
       "       [0.85444744, 0.14555256],\n",
       "       [0.99468085, 0.00531915],\n",
       "       [0.70634921, 0.29365079],\n",
       "       [0.45478036, 0.54521964],\n",
       "       [0.02910053, 0.97089947],\n",
       "       [0.82914573, 0.17085427],\n",
       "       [0.00526316, 0.99473684],\n",
       "       [0.99749373, 0.00250627],\n",
       "       [0.74677003, 0.25322997],\n",
       "       [0.99737533, 0.00262467],\n",
       "       [1.        , 0.        ],\n",
       "       [0.85751295, 0.14248705],\n",
       "       [0.2845953 , 0.7154047 ],\n",
       "       [0.13924051, 0.86075949],\n",
       "       [0.21727749, 0.78272251],\n",
       "       [0.        , 1.        ],\n",
       "       [0.75257732, 0.24742268],\n",
       "       [0.90201005, 0.09798995],\n",
       "       [0.04166667, 0.95833333],\n",
       "       [0.99484536, 0.00515464],\n",
       "       [0.96560847, 0.03439153],\n",
       "       [0.99733333, 0.00266667],\n",
       "       [0.00262467, 0.99737533],\n",
       "       [0.05194805, 0.94805195],\n",
       "       [0.92207792, 0.07792208],\n",
       "       [0.93506494, 0.06493506],\n",
       "       [0.99202128, 0.00797872],\n",
       "       [0.22432432, 0.77567568],\n",
       "       [0.9871134 , 0.0128866 ],\n",
       "       [0.136     , 0.864     ],\n",
       "       [0.93667546, 0.06332454],\n",
       "       [0.07068063, 0.92931937],\n",
       "       [0.98655914, 0.01344086],\n",
       "       [0.98915989, 0.01084011],\n",
       "       [0.9870801 , 0.0129199 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.93733681, 0.06266319],\n",
       "       [0.01282051, 0.98717949],\n",
       "       [0.05974026, 0.94025974],\n",
       "       [0.05820106, 0.94179894],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.9762533 , 0.0237467 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95275591, 0.04724409],\n",
       "       [0.06753247, 0.93246753],\n",
       "       [0.99473684, 0.00526316],\n",
       "       [0.22105263, 0.77894737],\n",
       "       [0.00263158, 0.99736842],\n",
       "       [0.06100796, 0.93899204],\n",
       "       [0.        , 1.        ],\n",
       "       [0.82666667, 0.17333333],\n",
       "       [0.08542714, 0.91457286],\n",
       "       [0.12944162, 0.87055838],\n",
       "       [1.        , 0.        ],\n",
       "       [0.91666667, 0.08333333],\n",
       "       [0.2025974 , 0.7974026 ],\n",
       "       [0.93654822, 0.06345178],\n",
       "       [0.04461942, 0.95538058],\n",
       "       [0.12188366, 0.87811634],\n",
       "       [0.99730458, 0.00269542],\n",
       "       [0.91326531, 0.08673469],\n",
       "       [0.57402597, 0.42597403],\n",
       "       [0.8880597 , 0.1119403 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03674541, 0.96325459],\n",
       "       [0.93899204, 0.06100796],\n",
       "       [0.03794038, 0.96205962],\n",
       "       [0.12051282, 0.87948718],\n",
       "       [0.94373402, 0.05626598],\n",
       "       [1.        , 0.        ],\n",
       "       [0.05540897, 0.94459103],\n",
       "       [0.70379747, 0.29620253]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators = 500, max_leaf_nodes = 16, n_jobs = -1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important\n",
    "\n",
    "The following BaggingClassifier is roughly equivalent to the previous RandomForestClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "                            DecisionTreeClassifier(splitter = \"random\", max_leaf_nodes = 16),\n",
    "                            n_estimators = 500, max_samples = 1.0, bootstrap = True, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.fit(X_train, y_train)\n",
    "accuracy_score(bag_clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
