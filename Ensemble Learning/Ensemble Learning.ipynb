{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(solver=\"liblinear\")\n",
    "svm = SVC(gamma=\"auto\")\n",
    "random_forest = RandomForestClassifier(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "                            estimators = [('lr', log_reg), ('rf', random_forest), ('svc', svm)],\n",
    "                            voting = \"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='liblinear', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='g...\n",
       "                                                     n_jobs=None,\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=None,\n",
       "                                                     verbose=0,\n",
       "                                                     warm_start=False)),\n",
       "                             ('svc',\n",
       "                              SVC(C=1.0, cache_size=200, class_weight=None,\n",
       "                                  coef0=0.0, decision_function_shape='ovr',\n",
       "                                  degree=3, gamma='auto', kernel='rbf',\n",
       "                                  max_iter=-1, probability=False,\n",
       "                                  random_state=None, shrinking=True, tol=0.001,\n",
       "                                  verbose=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "SVC 0.888\n",
      "RandomForestClassifier 0.856\n",
      "VotingClassifier 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_reg, svm, random_forest, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(solver=\"liblinear\")\n",
    "svm = SVC(gamma=\"auto\", probability = True)\n",
    "random_forest = RandomForestClassifier(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "                            estimators = [('lr', log_reg), ('rf', random_forest), ('svc', svm)],\n",
    "                            voting = \"soft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                        criterion='gini',\n",
       "                                                        max_depth=None,\n",
       "                                                        max_features=None,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=1,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        presort=False,\n",
       "                                                        random_state=None,\n",
       "                                                        splitter='best'),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                  max_samples=100, n_estimators=500, n_jobs=-1, oob_score=True,\n",
       "                  random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "                            DecisionTreeClassifier(), n_estimators = 500,\n",
    "                            max_samples = 100, bootstrap = True, n_jobs = -1, oob_score = True)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.928"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37726098, 0.62273902],\n",
       "       [0.39583333, 0.60416667],\n",
       "       [1.        , 0.        ],\n",
       "       [0.008     , 0.992     ],\n",
       "       [0.01902174, 0.98097826],\n",
       "       [0.11082474, 0.88917526],\n",
       "       [0.41909814, 0.58090186],\n",
       "       [0.06005222, 0.93994778],\n",
       "       [0.93888889, 0.06111111],\n",
       "       [0.8515625 , 0.1484375 ],\n",
       "       [0.54636591, 0.45363409],\n",
       "       [0.0390625 , 0.9609375 ],\n",
       "       [0.74615385, 0.25384615],\n",
       "       [0.85449735, 0.14550265],\n",
       "       [0.89420655, 0.10579345],\n",
       "       [0.08423913, 0.91576087],\n",
       "       [0.03439153, 0.96560847],\n",
       "       [0.92972973, 0.07027027],\n",
       "       [0.67010309, 0.32989691],\n",
       "       [0.97043011, 0.02956989],\n",
       "       [0.05221932, 0.94778068],\n",
       "       [0.2434555 , 0.7565445 ],\n",
       "       [0.88579387, 0.11420613],\n",
       "       [0.99234694, 0.00765306],\n",
       "       [0.96216216, 0.03783784],\n",
       "       [0.00529101, 0.99470899],\n",
       "       [0.98172324, 0.01827676],\n",
       "       [0.9972752 , 0.0027248 ],\n",
       "       [0.02717391, 0.97282609],\n",
       "       [0.7020202 , 0.2979798 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99739583, 0.00260417],\n",
       "       [0.0234375 , 0.9765625 ],\n",
       "       [0.08510638, 0.91489362],\n",
       "       [0.12911392, 0.87088608],\n",
       "       [0.97382199, 0.02617801],\n",
       "       [0.01061008, 0.98938992],\n",
       "       [0.58510638, 0.41489362],\n",
       "       [0.02842377, 0.97157623],\n",
       "       [0.9973822 , 0.0026178 ],\n",
       "       [0.10614525, 0.89385475],\n",
       "       [0.40364583, 0.59635417],\n",
       "       [0.99731183, 0.00268817],\n",
       "       [0.97574124, 0.02425876],\n",
       "       [0.01558442, 0.98441558],\n",
       "       [0.99468085, 0.00531915],\n",
       "       [1.        , 0.        ],\n",
       "       [0.06299213, 0.93700787],\n",
       "       [0.98734177, 0.01265823],\n",
       "       [0.04668305, 0.95331695],\n",
       "       [0.94960212, 0.05039788],\n",
       "       [0.85390428, 0.14609572],\n",
       "       [0.89487871, 0.10512129],\n",
       "       [0.80310881, 0.19689119],\n",
       "       [0.02173913, 0.97826087],\n",
       "       [0.06266319, 0.93733681],\n",
       "       [0.86089239, 0.13910761],\n",
       "       [0.01086957, 0.98913043],\n",
       "       [0.00815217, 0.99184783],\n",
       "       [0.07377049, 0.92622951],\n",
       "       [0.88095238, 0.11904762],\n",
       "       [0.64229765, 0.35770235],\n",
       "       [0.70967742, 0.29032258],\n",
       "       [0.99457995, 0.00542005],\n",
       "       [0.02624672, 0.97375328],\n",
       "       [0.80053191, 0.19946809],\n",
       "       [0.99457995, 0.00542005],\n",
       "       [0.99459459, 0.00540541],\n",
       "       [0.65586035, 0.34413965],\n",
       "       [0.97680412, 0.02319588],\n",
       "       [0.33928571, 0.66071429],\n",
       "       [0.28645833, 0.71354167],\n",
       "       [0.41116751, 0.58883249],\n",
       "       [0.65721649, 0.34278351],\n",
       "       [0.01312336, 0.98687664],\n",
       "       [0.32712766, 0.67287234],\n",
       "       [0.88770053, 0.11229947],\n",
       "       [0.99740933, 0.00259067],\n",
       "       [0.04102564, 0.95897436],\n",
       "       [0.94933333, 0.05066667],\n",
       "       [0.01308901, 0.98691099],\n",
       "       [0.26153846, 0.73846154],\n",
       "       [0.14171123, 0.85828877],\n",
       "       [0.43410853, 0.56589147],\n",
       "       [0.9921671 , 0.0078329 ],\n",
       "       [0.04580153, 0.95419847],\n",
       "       [0.63476071, 0.36523929],\n",
       "       [0.06896552, 0.93103448],\n",
       "       [0.04497354, 0.95502646],\n",
       "       [0.00795756, 0.99204244],\n",
       "       [0.3324937 , 0.6675063 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02099738, 0.97900262],\n",
       "       [0.05076142, 0.94923858],\n",
       "       [0.01101928, 0.98898072],\n",
       "       [0.82198953, 0.17801047],\n",
       "       [0.64150943, 0.35849057],\n",
       "       [0.07387863, 0.92612137],\n",
       "       [1.        , 0.        ],\n",
       "       [0.3203125 , 0.6796875 ],\n",
       "       [0.67362924, 0.32637076],\n",
       "       [0.00771208, 0.99228792],\n",
       "       [0.10282776, 0.89717224],\n",
       "       [0.43699732, 0.56300268],\n",
       "       [0.9742268 , 0.0257732 ],\n",
       "       [0.05882353, 0.94117647],\n",
       "       [0.98404255, 0.01595745],\n",
       "       [0.45953003, 0.54046997],\n",
       "       [0.31377551, 0.68622449],\n",
       "       [0.99742268, 0.00257732],\n",
       "       [0.25729443, 0.74270557],\n",
       "       [0.86666667, 0.13333333],\n",
       "       [0.29569892, 0.70430108],\n",
       "       [0.75696203, 0.24303797],\n",
       "       [0.9973545 , 0.0026455 ],\n",
       "       [0.99266504, 0.00733496],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.50127877, 0.49872123],\n",
       "       [0.9919571 , 0.0080429 ],\n",
       "       [0.09408602, 0.90591398],\n",
       "       [0.98737374, 0.01262626],\n",
       "       [0.97900262, 0.02099738],\n",
       "       [0.99719888, 0.00280112],\n",
       "       [0.95854922, 0.04145078],\n",
       "       [0.98138298, 0.01861702],\n",
       "       [0.03865979, 0.96134021],\n",
       "       [0.92875318, 0.07124682],\n",
       "       [0.96700508, 0.03299492],\n",
       "       [0.02406417, 0.97593583],\n",
       "       [0.25974026, 0.74025974],\n",
       "       [0.83291139, 0.16708861],\n",
       "       [0.39322917, 0.60677083],\n",
       "       [0.93814433, 0.06185567],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03076923, 0.96923077],\n",
       "       [0.78371501, 0.21628499],\n",
       "       [0.73869347, 0.26130653],\n",
       "       [0.52673797, 0.47326203],\n",
       "       [0.8626943 , 0.1373057 ],\n",
       "       [0.89095745, 0.10904255],\n",
       "       [0.12368421, 0.87631579],\n",
       "       [0.77694236, 0.22305764],\n",
       "       [0.03485255, 0.96514745],\n",
       "       [0.01574803, 0.98425197],\n",
       "       [0.12335958, 0.87664042],\n",
       "       [0.78350515, 0.21649485],\n",
       "       [0.96401028, 0.03598972],\n",
       "       [1.        , 0.        ],\n",
       "       [0.04712042, 0.95287958],\n",
       "       [0.00789474, 0.99210526],\n",
       "       [0.06544503, 0.93455497],\n",
       "       [0.02272727, 0.97727273],\n",
       "       [0.99751244, 0.00248756],\n",
       "       [0.97843666, 0.02156334],\n",
       "       [0.88372093, 0.11627907],\n",
       "       [0.99498747, 0.00501253],\n",
       "       [0.99742931, 0.00257069],\n",
       "       [0.90740741, 0.09259259],\n",
       "       [0.0074813 , 0.9925187 ],\n",
       "       [0.71025641, 0.28974359],\n",
       "       [0.31139241, 0.68860759],\n",
       "       [0.06842105, 0.93157895],\n",
       "       [0.01481481, 0.98518519],\n",
       "       [0.37172775, 0.62827225],\n",
       "       [0.99480519, 0.00519481],\n",
       "       [0.97245179, 0.02754821],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98950131, 0.01049869],\n",
       "       [0.07591623, 0.92408377],\n",
       "       [0.00526316, 0.99473684],\n",
       "       [0.90439276, 0.09560724],\n",
       "       [0.02331606, 0.97668394],\n",
       "       [0.01256281, 0.98743719],\n",
       "       [0.99736842, 0.00263158],\n",
       "       [0.04145078, 0.95854922],\n",
       "       [0.82323232, 0.17676768],\n",
       "       [0.91160221, 0.08839779],\n",
       "       [0.0474934 , 0.9525066 ],\n",
       "       [0.94764398, 0.05235602],\n",
       "       [0.9071618 , 0.0928382 ],\n",
       "       [0.97900262, 0.02099738],\n",
       "       [0.01578947, 0.98421053],\n",
       "       [0.02272727, 0.97727273],\n",
       "       [0.99753086, 0.00246914],\n",
       "       [0.24473684, 0.75526316],\n",
       "       [1.        , 0.        ],\n",
       "       [0.09809264, 0.90190736],\n",
       "       [0.03141361, 0.96858639],\n",
       "       [0.9843342 , 0.0156658 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.16751269, 0.83248731],\n",
       "       [0.8984375 , 0.1015625 ],\n",
       "       [0.89817232, 0.10182768],\n",
       "       [0.60621762, 0.39378238],\n",
       "       [0.70557029, 0.29442971],\n",
       "       [0.02051282, 0.97948718],\n",
       "       [0.24421594, 0.75578406],\n",
       "       [0.98205128, 0.01794872],\n",
       "       [0.91246684, 0.08753316],\n",
       "       [0.93085106, 0.06914894],\n",
       "       [0.97580645, 0.02419355],\n",
       "       [0.03947368, 0.96052632],\n",
       "       [0.01023018, 0.98976982],\n",
       "       [0.0971867 , 0.9028133 ],\n",
       "       [0.51923077, 0.48076923],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03217158, 0.96782842],\n",
       "       [0.9742268 , 0.0257732 ],\n",
       "       [0.10928962, 0.89071038],\n",
       "       [0.12041885, 0.87958115],\n",
       "       [0.91304348, 0.08695652],\n",
       "       [0.06169666, 0.93830334],\n",
       "       [0.33423181, 0.66576819],\n",
       "       [0.015625  , 0.984375  ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01522843, 0.98477157],\n",
       "       [0.01005025, 0.98994975],\n",
       "       [0.91869919, 0.08130081],\n",
       "       [0.89893617, 0.10106383],\n",
       "       [0.96373057, 0.03626943],\n",
       "       [0.00775194, 0.99224806],\n",
       "       [0.08093995, 0.91906005],\n",
       "       [0.94897959, 0.05102041],\n",
       "       [0.12598425, 0.87401575],\n",
       "       [0.01269036, 0.98730964],\n",
       "       [0.28860759, 0.71139241],\n",
       "       [0.97127937, 0.02872063],\n",
       "       [0.85333333, 0.14666667],\n",
       "       [0.12401055, 0.87598945],\n",
       "       [0.76744186, 0.23255814],\n",
       "       [0.94936709, 0.05063291],\n",
       "       [0.13164557, 0.86835443],\n",
       "       [0.12307692, 0.87692308],\n",
       "       [0.98666667, 0.01333333],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01574803, 0.98425197],\n",
       "       [0.01049869, 0.98950131],\n",
       "       [0.31331593, 0.68668407],\n",
       "       [0.83333333, 0.16666667],\n",
       "       [0.04896907, 0.95103093],\n",
       "       [0.97900262, 0.02099738],\n",
       "       [0.89124668, 0.10875332],\n",
       "       [0.0078534 , 0.9921466 ],\n",
       "       [0.78181818, 0.21818182],\n",
       "       [0.99240506, 0.00759494],\n",
       "       [0.00769231, 0.99230769],\n",
       "       [0.99744898, 0.00255102],\n",
       "       [0.06345178, 0.93654822],\n",
       "       [0.00773196, 0.99226804],\n",
       "       [0.09814324, 0.90185676],\n",
       "       [0.22459893, 0.77540107],\n",
       "       [0.85215054, 0.14784946],\n",
       "       [0.06878307, 0.93121693],\n",
       "       [0.99242424, 0.00757576],\n",
       "       [0.67024129, 0.32975871],\n",
       "       [0.10344828, 0.89655172],\n",
       "       [0.67813268, 0.32186732],\n",
       "       [0.84358974, 0.15641026],\n",
       "       [0.01298701, 0.98701299],\n",
       "       [0.99738903, 0.00261097],\n",
       "       [0.02487562, 0.97512438],\n",
       "       [0.        , 1.        ],\n",
       "       [0.74873096, 0.25126904],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98481013, 0.01518987],\n",
       "       [0.12113402, 0.87886598],\n",
       "       [0.76982097, 0.23017903],\n",
       "       [0.13810742, 0.86189258],\n",
       "       [0.99725275, 0.00274725],\n",
       "       [0.88607595, 0.11392405],\n",
       "       [0.01574803, 0.98425197],\n",
       "       [0.09585492, 0.90414508],\n",
       "       [0.1356383 , 0.8643617 ],\n",
       "       [0.09207161, 0.90792839],\n",
       "       [0.        , 1.        ],\n",
       "       [0.96514745, 0.03485255],\n",
       "       [0.82019704, 0.17980296],\n",
       "       [0.21409922, 0.78590078],\n",
       "       [0.93506494, 0.06493506],\n",
       "       [0.04438642, 0.95561358],\n",
       "       [0.59480519, 0.40519481],\n",
       "       [0.14324324, 0.85675676],\n",
       "       [0.95090439, 0.04909561],\n",
       "       [0.88461538, 0.11538462],\n",
       "       [0.01767677, 0.98232323],\n",
       "       [0.95454545, 0.04545455],\n",
       "       [0.87239583, 0.12760417],\n",
       "       [0.01222494, 0.98777506],\n",
       "       [0.06403941, 0.93596059],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0437018 , 0.9562982 ],\n",
       "       [0.9973262 , 0.0026738 ],\n",
       "       [0.08707124, 0.91292876],\n",
       "       [0.89304813, 0.10695187],\n",
       "       [0.99745547, 0.00254453],\n",
       "       [0.00529101, 0.99470899],\n",
       "       [0.0479798 , 0.9520202 ],\n",
       "       [0.66493506, 0.33506494],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.66846361, 0.33153639],\n",
       "       [0.85294118, 0.14705882],\n",
       "       [0.99730458, 0.00269542],\n",
       "       [0.67539267, 0.32460733],\n",
       "       [0.46049046, 0.53950954],\n",
       "       [0.03316327, 0.96683673],\n",
       "       [0.80964467, 0.19035533],\n",
       "       [0.00779221, 0.99220779],\n",
       "       [1.        , 0.        ],\n",
       "       [0.76021798, 0.23978202],\n",
       "       [0.99728261, 0.00271739],\n",
       "       [1.        , 0.        ],\n",
       "       [0.8292011 , 0.1707989 ],\n",
       "       [0.2591623 , 0.7408377 ],\n",
       "       [0.15025907, 0.84974093],\n",
       "       [0.20478723, 0.79521277],\n",
       "       [0.        , 1.        ],\n",
       "       [0.75191816, 0.24808184],\n",
       "       [0.8707124 , 0.1292876 ],\n",
       "       [0.0530504 , 0.9469496 ],\n",
       "       [0.99741602, 0.00258398],\n",
       "       [0.95956873, 0.04043127],\n",
       "       [0.99734748, 0.00265252],\n",
       "       [0.01072386, 0.98927614],\n",
       "       [0.07455013, 0.92544987],\n",
       "       [0.90231362, 0.09768638],\n",
       "       [0.90785908, 0.09214092],\n",
       "       [0.99484536, 0.00515464],\n",
       "       [0.22911051, 0.77088949],\n",
       "       [0.9867374 , 0.0132626 ],\n",
       "       [0.15696203, 0.84303797],\n",
       "       [0.9375    , 0.0625    ],\n",
       "       [0.056     , 0.944     ],\n",
       "       [0.97938144, 0.02061856],\n",
       "       [0.99477807, 0.00522193],\n",
       "       [0.99232737, 0.00767263],\n",
       "       [0.00258398, 0.99741602],\n",
       "       [0.94535519, 0.05464481],\n",
       "       [0.02362205, 0.97637795],\n",
       "       [0.06185567, 0.93814433],\n",
       "       [0.05943152, 0.94056848],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98200514, 0.01799486],\n",
       "       [0.        , 1.        ],\n",
       "       [0.94750656, 0.05249344],\n",
       "       [0.07575758, 0.92424242],\n",
       "       [0.98429319, 0.01570681],\n",
       "       [0.22459893, 0.77540107],\n",
       "       [0.00795756, 0.99204244],\n",
       "       [0.06266319, 0.93733681],\n",
       "       [0.        , 1.        ],\n",
       "       [0.79220779, 0.20779221],\n",
       "       [0.07341772, 0.92658228],\n",
       "       [0.12787724, 0.87212276],\n",
       "       [0.99738903, 0.00261097],\n",
       "       [0.90932642, 0.09067358],\n",
       "       [0.22631579, 0.77368421],\n",
       "       [0.94164456, 0.05835544],\n",
       "       [0.08648649, 0.91351351],\n",
       "       [0.128     , 0.872     ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.90789474, 0.09210526],\n",
       "       [0.54707379, 0.45292621],\n",
       "       [0.89693593, 0.10306407],\n",
       "       [0.99730458, 0.00269542],\n",
       "       [0.06476684, 0.93523316],\n",
       "       [0.95189873, 0.04810127],\n",
       "       [0.03457447, 0.96542553],\n",
       "       [0.15099715, 0.84900285],\n",
       "       [0.90932642, 0.09067358],\n",
       "       [1.        , 0.        ],\n",
       "       [0.08355795, 0.91644205],\n",
       "       [0.7277628 , 0.2722372 ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators = 500, max_leaf_nodes = 16, n_jobs = -1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important\n",
    "\n",
    "The following BaggingClassifier is roughly equivalent to the previous RandomForestClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "                            DecisionTreeClassifier(splitter = \"random\", max_leaf_nodes = 16),\n",
    "                            n_estimators = 500, max_samples = 1.0, bootstrap = True, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.fit(X_train, y_train)\n",
    "accuracy_score(bag_clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=1,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort=False,\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=0.5, n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "                            DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "                            algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ada_clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=42, splitter='best')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=42, splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = y - tree_reg1.predict(X)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg2.fit(X, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=42, splitter='best')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3 = y2 - tree_reg2.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg3.fit(X, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[0.8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75026781])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting with early stopping\n",
    "Instead of performing Gradient Boosting manually, you can use method from sklearn `GradientBoostingRegressor`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=2,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=120,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth = 2, n_estimators = 120)\n",
    "gbrt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [mean_squared_error(y_val, y_pred) for y_pred in gbrt.staged_predict(X_val)]\n",
    "bst_n_estimators = np.argmin(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.01, 0.07)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, len(errors)+1), errors, '-o', markersize = 2)\n",
    "plt.ylim([-0.01, 0.07])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=2,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=79,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrt_best = GradientBoostingRegressor(max_depth = 2, n_estimators = bst_n_estimators)\n",
    "gbrt_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth = 2, warm_start = True)\n",
    "\n",
    "min_val_error = np.float('inf')\n",
    "error_going_up = 0\n",
    "\n",
    "for n_estimators in range(1, 120):\n",
    "    gbrt.n_estimators = n_estimators\n",
    "    gbrt.fit(X_train, y_train)\n",
    "    y_pred = gbrt.predict(X_val)\n",
    "    val_error = mean_squared_error(y_pred, y_val)\n",
    "    \n",
    "    if val_error<min_val_error:\n",
    "        min_val_error = val_error\n",
    "        error_going_up = 0\n",
    "    else:\n",
    "        error_going_up +=1\n",
    "        if error_going_up == 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0026930464329994377"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_val_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrt.n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8\n",
    "\n",
    "Load the MNIST data (introduced in Chapter 3), and split it into a training set, a validation set, and a\n",
    "test set (e.g., use 40,000 instances for training, 10,000 for validation, and 10,000 for testing). Then\n",
    "train various classifiers, such as a Random Forest classifier, an Extra-Trees classifier, and an SVM.\n",
    "Next, try to combine them into an ensemble that outperforms them all on the validation set, using a\n",
    "soft or hard voting classifier. Once you have found one, try it on the test set. How much better does it\n",
    "perform compared to the individual classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(mnist.data, mnist.target, test_size = 10000)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators = 10)\n",
    "extra_trees = ExtraTreesClassifier(n_estimators = 10)\n",
    "svm_clf = LinearSVC()\n",
    "mlp_clf = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "Training the ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "                     oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Training the LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ajdin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "estimators = [random_forest, extra_trees, svm_clf]\n",
    "\n",
    "for estimator in estimators:\n",
    "    print(\"Training the\", estimator)\n",
    "    estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9474, 0.9486, 0.8484]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[estimator.score(X_val, y_val) for estimator in estimators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_estimators = [\n",
    "    ('random_forest_clf', random_forest),\n",
    "    ('ExtraTrees_clf', extra_trees),\n",
    "    (\"mlp_clf\", mlp_clf)\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vote_clf = VotingClassifier(named_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('random_forest_clf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features='auto',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=10,\n",
       "                                                     n_jobs=None,\n",
       "                                                     oob_score=False,\n",
       "                                                     random_sta...\n",
       "                                            beta_2=0.999, early_stopping=False,\n",
       "                                            epsilon=1e-08,\n",
       "                                            hidden_layer_sizes=(100,),\n",
       "                                            learning_rate='constant',\n",
       "                                            learning_rate_init=0.001,\n",
       "                                            max_iter=200, momentum=0.9,\n",
       "                                            n_iter_no_change=10,\n",
       "                                            nesterovs_momentum=True,\n",
       "                                            power_t=0.5, random_state=None,\n",
       "                                            shuffle=True, solver='adam',\n",
       "                                            tol=0.0001, validation_fraction=0.1,\n",
       "                                            verbose=False, warm_start=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9645"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_clf.voting = \"soft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9704"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
