{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(solver=\"liblinear\")\n",
    "svm = SVC(gamma=\"auto\")\n",
    "random_forest = RandomForestClassifier(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "                            estimators = [('lr', log_reg), ('rf', random_forest), ('svc', svm)],\n",
    "                            voting = \"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='liblinear', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='g...\n",
       "                                                     n_jobs=None,\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=None,\n",
       "                                                     verbose=0,\n",
       "                                                     warm_start=False)),\n",
       "                             ('svc',\n",
       "                              SVC(C=1.0, cache_size=200, class_weight=None,\n",
       "                                  coef0=0.0, decision_function_shape='ovr',\n",
       "                                  degree=3, gamma='auto', kernel='rbf',\n",
       "                                  max_iter=-1, probability=False,\n",
       "                                  random_state=None, shrinking=True, tol=0.001,\n",
       "                                  verbose=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "SVC 0.888\n",
      "RandomForestClassifier 0.912\n",
      "VotingClassifier 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_reg, svm, random_forest, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(solver=\"liblinear\")\n",
    "svm = SVC(gamma=\"auto\", probability = True)\n",
    "random_forest = RandomForestClassifier(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "                            estimators = [('lr', log_reg), ('rf', random_forest), ('svc', svm)],\n",
    "                            voting = \"soft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                        criterion='gini',\n",
       "                                                        max_depth=None,\n",
       "                                                        max_features=None,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=1,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        presort=False,\n",
       "                                                        random_state=None,\n",
       "                                                        splitter='best'),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                  max_samples=100, n_estimators=500, n_jobs=-1, oob_score=True,\n",
       "                  random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "                            DecisionTreeClassifier(), n_estimators = 500,\n",
    "                            max_samples = 100, bootstrap = True, n_jobs = -1, oob_score = True)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9253333333333333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31382979, 0.68617021],\n",
       "       [0.37988827, 0.62011173],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01017812, 0.98982188],\n",
       "       [0.02356021, 0.97643979],\n",
       "       [0.1043956 , 0.8956044 ],\n",
       "       [0.41361257, 0.58638743],\n",
       "       [0.06426735, 0.93573265],\n",
       "       [0.94545455, 0.05454545],\n",
       "       [0.85365854, 0.14634146],\n",
       "       [0.58900524, 0.41099476],\n",
       "       [0.03252033, 0.96747967],\n",
       "       [0.72135417, 0.27864583],\n",
       "       [0.845953  , 0.154047  ],\n",
       "       [0.91798942, 0.08201058],\n",
       "       [0.11263736, 0.88736264],\n",
       "       [0.03626943, 0.96373057],\n",
       "       [0.92447917, 0.07552083],\n",
       "       [0.68010076, 0.31989924],\n",
       "       [0.96683673, 0.03316327],\n",
       "       [0.04485488, 0.95514512],\n",
       "       [0.25714286, 0.74285714],\n",
       "       [0.86387435, 0.13612565],\n",
       "       [0.99469496, 0.00530504],\n",
       "       [0.95348837, 0.04651163],\n",
       "       [0.00277008, 0.99722992],\n",
       "       [0.9721519 , 0.0278481 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02763819, 0.97236181],\n",
       "       [0.73684211, 0.26315789],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99736842, 0.00263158],\n",
       "       [0.01285347, 0.98714653],\n",
       "       [0.06951872, 0.93048128],\n",
       "       [0.08838384, 0.91161616],\n",
       "       [0.9726776 , 0.0273224 ],\n",
       "       [0.008     , 0.992     ],\n",
       "       [0.56878307, 0.43121693],\n",
       "       [0.00757576, 0.99242424],\n",
       "       [1.        , 0.        ],\n",
       "       [0.08923885, 0.91076115],\n",
       "       [0.34508816, 0.65491184],\n",
       "       [0.98701299, 0.01298701],\n",
       "       [0.99226804, 0.00773196],\n",
       "       [0.01041667, 0.98958333],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.06084656, 0.93915344],\n",
       "       [0.98205128, 0.01794872],\n",
       "       [0.04473684, 0.95526316],\n",
       "       [0.93246753, 0.06753247],\n",
       "       [0.86734694, 0.13265306],\n",
       "       [0.91688312, 0.08311688],\n",
       "       [0.83080808, 0.16919192],\n",
       "       [0.015625  , 0.984375  ],\n",
       "       [0.10353535, 0.89646465],\n",
       "       [0.83827493, 0.16172507],\n",
       "       [0.0078329 , 0.9921671 ],\n",
       "       [0.01612903, 0.98387097],\n",
       "       [0.04427083, 0.95572917],\n",
       "       [0.85411141, 0.14588859],\n",
       "       [0.62599469, 0.37400531],\n",
       "       [0.68475452, 0.31524548],\n",
       "       [0.98245614, 0.01754386],\n",
       "       [0.01033592, 0.98966408],\n",
       "       [0.82687339, 0.17312661],\n",
       "       [0.98172324, 0.01827676],\n",
       "       [0.9973545 , 0.0026455 ],\n",
       "       [0.60949868, 0.39050132],\n",
       "       [0.9769821 , 0.0230179 ],\n",
       "       [0.35897436, 0.64102564],\n",
       "       [0.30829016, 0.69170984],\n",
       "       [0.44892473, 0.55107527],\n",
       "       [0.68112245, 0.31887755],\n",
       "       [0.0026178 , 0.9973822 ],\n",
       "       [0.34102564, 0.65897436],\n",
       "       [0.87401575, 0.12598425],\n",
       "       [1.        , 0.        ],\n",
       "       [0.04303797, 0.95696203],\n",
       "       [0.95865633, 0.04134367],\n",
       "       [0.0106383 , 0.9893617 ],\n",
       "       [0.23607427, 0.76392573],\n",
       "       [0.13783784, 0.86216216],\n",
       "       [0.4961039 , 0.5038961 ],\n",
       "       [0.99460916, 0.00539084],\n",
       "       [0.03448276, 0.96551724],\n",
       "       [0.66751269, 0.33248731],\n",
       "       [0.048     , 0.952     ],\n",
       "       [0.03069054, 0.96930946],\n",
       "       [0.00253807, 0.99746193],\n",
       "       [0.36243386, 0.63756614],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01020408, 0.98979592],\n",
       "       [0.0599455 , 0.9400545 ],\n",
       "       [0.01570681, 0.98429319],\n",
       "       [0.81443299, 0.18556701],\n",
       "       [0.6351706 , 0.3648294 ],\n",
       "       [0.06299213, 0.93700787],\n",
       "       [1.        , 0.        ],\n",
       "       [0.33157895, 0.66842105],\n",
       "       [0.72413793, 0.27586207],\n",
       "       [0.0026455 , 0.9973545 ],\n",
       "       [0.09162304, 0.90837696],\n",
       "       [0.48167539, 0.51832461],\n",
       "       [0.97089947, 0.02910053],\n",
       "       [0.04644809, 0.95355191],\n",
       "       [0.97650131, 0.02349869],\n",
       "       [0.47916667, 0.52083333],\n",
       "       [0.31443299, 0.68556701],\n",
       "       [0.99736148, 0.00263852],\n",
       "       [0.20643432, 0.79356568],\n",
       "       [0.85215054, 0.14784946],\n",
       "       [0.27435897, 0.72564103],\n",
       "       [0.80661578, 0.19338422],\n",
       "       [0.99731183, 0.00268817],\n",
       "       [0.99466667, 0.00533333],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.49465241, 0.50534759],\n",
       "       [0.98663102, 0.01336898],\n",
       "       [0.07427056, 0.92572944],\n",
       "       [0.99191375, 0.00808625],\n",
       "       [0.95822454, 0.04177546],\n",
       "       [0.99744898, 0.00255102],\n",
       "       [0.94402036, 0.05597964],\n",
       "       [0.98172324, 0.01827676],\n",
       "       [0.03430079, 0.96569921],\n",
       "       [0.95384615, 0.04615385],\n",
       "       [0.96915167, 0.03084833],\n",
       "       [0.01308901, 0.98691099],\n",
       "       [0.2486631 , 0.7513369 ],\n",
       "       [0.86015831, 0.13984169],\n",
       "       [0.33915212, 0.66084788],\n",
       "       [0.90816327, 0.09183673],\n",
       "       [0.00247525, 0.99752475],\n",
       "       [0.03703704, 0.96296296],\n",
       "       [0.79683377, 0.20316623],\n",
       "       [0.72894737, 0.27105263],\n",
       "       [0.54188482, 0.45811518],\n",
       "       [0.84920635, 0.15079365],\n",
       "       [0.9383378 , 0.0616622 ],\n",
       "       [0.14936709, 0.85063291],\n",
       "       [0.77833753, 0.22166247],\n",
       "       [0.04065041, 0.95934959],\n",
       "       [0.01149425, 0.98850575],\n",
       "       [0.1152815 , 0.8847185 ],\n",
       "       [0.77260982, 0.22739018],\n",
       "       [0.96335079, 0.03664921],\n",
       "       [0.99739583, 0.00260417],\n",
       "       [0.0270936 , 0.9729064 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.08222812, 0.91777188],\n",
       "       [0.01832461, 0.98167539],\n",
       "       [0.9921875 , 0.0078125 ],\n",
       "       [0.98365123, 0.01634877],\n",
       "       [0.88235294, 0.11764706],\n",
       "       [0.99746193, 0.00253807],\n",
       "       [1.        , 0.        ],\n",
       "       [0.90274314, 0.09725686],\n",
       "       [0.01049869, 0.98950131],\n",
       "       [0.71059432, 0.28940568],\n",
       "       [0.34748011, 0.65251989],\n",
       "       [0.07774799, 0.92225201],\n",
       "       [0.01084011, 0.98915989],\n",
       "       [0.38903394, 0.61096606],\n",
       "       [0.99468085, 0.00531915],\n",
       "       [0.97354497, 0.02645503],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97900262, 0.02099738],\n",
       "       [0.06060606, 0.93939394],\n",
       "       [0.00522193, 0.99477807],\n",
       "       [0.93684211, 0.06315789],\n",
       "       [0.01298701, 0.98701299],\n",
       "       [0.0025974 , 0.9974026 ],\n",
       "       [0.9974026 , 0.0025974 ],\n",
       "       [0.04134367, 0.95865633],\n",
       "       [0.79898219, 0.20101781],\n",
       "       [0.90410959, 0.09589041],\n",
       "       [0.05235602, 0.94764398],\n",
       "       [0.94845361, 0.05154639],\n",
       "       [0.90979381, 0.09020619],\n",
       "       [0.97574124, 0.02425876],\n",
       "       [0.01340483, 0.98659517],\n",
       "       [0.01269036, 0.98730964],\n",
       "       [0.9973822 , 0.0026178 ],\n",
       "       [0.25729443, 0.74270557],\n",
       "       [0.99212598, 0.00787402],\n",
       "       [0.1038961 , 0.8961039 ],\n",
       "       [0.02244389, 0.97755611],\n",
       "       [0.98974359, 0.01025641],\n",
       "       [0.        , 1.        ],\n",
       "       [0.18527919, 0.81472081],\n",
       "       [0.90488432, 0.09511568],\n",
       "       [0.89141414, 0.10858586],\n",
       "       [0.61081081, 0.38918919],\n",
       "       [0.69350649, 0.30649351],\n",
       "       [0.0302267 , 0.9697733 ],\n",
       "       [0.27688172, 0.72311828],\n",
       "       [0.9871134 , 0.0128866 ],\n",
       "       [0.92307692, 0.07692308],\n",
       "       [0.91111111, 0.08888889],\n",
       "       [0.97674419, 0.02325581],\n",
       "       [0.05039788, 0.94960212],\n",
       "       [0.01061008, 0.98938992],\n",
       "       [0.09308511, 0.90691489],\n",
       "       [0.51498638, 0.48501362],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02387268, 0.97612732],\n",
       "       [0.97429306, 0.02570694],\n",
       "       [0.09259259, 0.90740741],\n",
       "       [0.11111111, 0.88888889],\n",
       "       [0.87121212, 0.12878788],\n",
       "       [0.04947917, 0.95052083],\n",
       "       [0.33838384, 0.66161616],\n",
       "       [0.00992556, 0.99007444],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01086957, 0.98913043],\n",
       "       [0.00536193, 0.99463807],\n",
       "       [0.88721805, 0.11278195],\n",
       "       [0.87131367, 0.12868633],\n",
       "       [0.96596859, 0.03403141],\n",
       "       [0.01285347, 0.98714653],\n",
       "       [0.06138107, 0.93861893],\n",
       "       [0.95584416, 0.04415584],\n",
       "       [0.12765957, 0.87234043],\n",
       "       [0.00253165, 0.99746835],\n",
       "       [0.29023747, 0.70976253],\n",
       "       [0.96623377, 0.03376623],\n",
       "       [0.85340314, 0.14659686],\n",
       "       [0.10789474, 0.89210526],\n",
       "       [0.71649485, 0.28350515],\n",
       "       [0.93513514, 0.06486486],\n",
       "       [0.15675676, 0.84324324],\n",
       "       [0.13759214, 0.86240786],\n",
       "       [0.98395722, 0.01604278],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00773196, 0.99226804],\n",
       "       [0.01538462, 0.98461538],\n",
       "       [0.36910995, 0.63089005],\n",
       "       [0.84196185, 0.15803815],\n",
       "       [0.03412073, 0.96587927],\n",
       "       [0.98958333, 0.01041667],\n",
       "       [0.86632391, 0.13367609],\n",
       "       [0.        , 1.        ],\n",
       "       [0.77929155, 0.22070845],\n",
       "       [0.99477807, 0.00522193],\n",
       "       [0.0052356 , 0.9947644 ],\n",
       "       [0.98921833, 0.01078167],\n",
       "       [0.05955335, 0.94044665],\n",
       "       [0.00510204, 0.99489796],\n",
       "       [0.12405063, 0.87594937],\n",
       "       [0.24932976, 0.75067024],\n",
       "       [0.8814433 , 0.1185567 ],\n",
       "       [0.07751938, 0.92248062],\n",
       "       [0.98404255, 0.01595745],\n",
       "       [0.68146214, 0.31853786],\n",
       "       [0.12944162, 0.87055838],\n",
       "       [0.61460957, 0.38539043],\n",
       "       [0.8368984 , 0.1631016 ],\n",
       "       [0.01767677, 0.98232323],\n",
       "       [0.99741602, 0.00258398],\n",
       "       [0.01098901, 0.98901099],\n",
       "       [0.        , 1.        ],\n",
       "       [0.79166667, 0.20833333],\n",
       "       [0.        , 1.        ],\n",
       "       [0.9921671 , 0.0078329 ],\n",
       "       [0.10997442, 0.89002558],\n",
       "       [0.77862595, 0.22137405],\n",
       "       [0.15601023, 0.84398977],\n",
       "       [0.9973262 , 0.0026738 ],\n",
       "       [0.88148148, 0.11851852],\n",
       "       [0.01038961, 0.98961039],\n",
       "       [0.08196721, 0.91803279],\n",
       "       [0.13471503, 0.86528497],\n",
       "       [0.09018568, 0.90981432],\n",
       "       [0.00255102, 0.99744898],\n",
       "       [0.97894737, 0.02105263],\n",
       "       [0.86885246, 0.13114754],\n",
       "       [0.18848168, 0.81151832],\n",
       "       [0.92227979, 0.07772021],\n",
       "       [0.05804749, 0.94195251],\n",
       "       [0.61007958, 0.38992042],\n",
       "       [0.15748031, 0.84251969],\n",
       "       [0.95710456, 0.04289544],\n",
       "       [0.90237467, 0.09762533],\n",
       "       [0.01084011, 0.98915989],\n",
       "       [0.94652406, 0.05347594],\n",
       "       [0.8714653 , 0.1285347 ],\n",
       "       [0.00269542, 0.99730458],\n",
       "       [0.06332454, 0.93667546],\n",
       "       [1.        , 0.        ],\n",
       "       [0.04427083, 0.95572917],\n",
       "       [0.98979592, 0.01020408],\n",
       "       [0.08651399, 0.91348601],\n",
       "       [0.89322917, 0.10677083],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00530504, 0.99469496],\n",
       "       [0.0397878 , 0.9602122 ],\n",
       "       [0.6802168 , 0.3197832 ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.69767442, 0.30232558],\n",
       "       [0.8715847 , 0.1284153 ],\n",
       "       [0.99742268, 0.00257732],\n",
       "       [0.68648649, 0.31351351],\n",
       "       [0.47258486, 0.52741514],\n",
       "       [0.02604167, 0.97395833],\n",
       "       [0.83289817, 0.16710183],\n",
       "       [0.0052356 , 0.9947644 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.77329975, 0.22670025],\n",
       "       [0.98677249, 0.01322751],\n",
       "       [0.99736148, 0.00263852],\n",
       "       [0.83776596, 0.16223404],\n",
       "       [0.30769231, 0.69230769],\n",
       "       [0.16020672, 0.83979328],\n",
       "       [0.26052632, 0.73947368],\n",
       "       [0.00273973, 0.99726027],\n",
       "       [0.75189873, 0.24810127],\n",
       "       [0.87760417, 0.12239583],\n",
       "       [0.05684755, 0.94315245],\n",
       "       [0.99731903, 0.00268097],\n",
       "       [0.96      , 0.04      ],\n",
       "       [0.98918919, 0.01081081],\n",
       "       [0.00265957, 0.99734043],\n",
       "       [0.07989691, 0.92010309],\n",
       "       [0.91392405, 0.08607595],\n",
       "       [0.9047619 , 0.0952381 ],\n",
       "       [0.99466667, 0.00533333],\n",
       "       [0.27480916, 0.72519084],\n",
       "       [0.99262899, 0.00737101],\n",
       "       [0.12765957, 0.87234043],\n",
       "       [0.93850267, 0.06149733],\n",
       "       [0.04415584, 0.95584416],\n",
       "       [0.98697917, 0.01302083],\n",
       "       [0.99731183, 0.00268817],\n",
       "       [0.992     , 0.008     ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.93005181, 0.06994819],\n",
       "       [0.02056555, 0.97943445],\n",
       "       [0.05804749, 0.94195251],\n",
       "       [0.05929919, 0.94070081],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99742268, 0.00257732],\n",
       "       [0.98704663, 0.01295337],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95514512, 0.04485488],\n",
       "       [0.07049608, 0.92950392],\n",
       "       [0.984375  , 0.015625  ],\n",
       "       [0.21683673, 0.78316327],\n",
       "       [0.00255754, 0.99744246],\n",
       "       [0.05583756, 0.94416244],\n",
       "       [0.0026178 , 0.9973822 ],\n",
       "       [0.83204134, 0.16795866],\n",
       "       [0.0678392 , 0.9321608 ],\n",
       "       [0.15803109, 0.84196891],\n",
       "       [0.9973262 , 0.0026738 ],\n",
       "       [0.94710327, 0.05289673],\n",
       "       [0.21808511, 0.78191489],\n",
       "       [0.96042216, 0.03957784],\n",
       "       [0.05555556, 0.94444444],\n",
       "       [0.10714286, 0.89285714],\n",
       "       [0.99726776, 0.00273224],\n",
       "       [0.93169399, 0.06830601],\n",
       "       [0.54591837, 0.45408163],\n",
       "       [0.86898396, 0.13101604],\n",
       "       [0.99740933, 0.00259067],\n",
       "       [0.03448276, 0.96551724],\n",
       "       [0.95628415, 0.04371585],\n",
       "       [0.03466667, 0.96533333],\n",
       "       [0.12658228, 0.87341772],\n",
       "       [0.93638677, 0.06361323],\n",
       "       [1.        , 0.        ],\n",
       "       [0.07631579, 0.92368421],\n",
       "       [0.67213115, 0.32786885]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators = 500, max_leaf_nodes = 16, n_jobs = -1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important\n",
    "\n",
    "The following BaggingClassifier is roughly equivalent to the previous RandomForestClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "                            DecisionTreeClassifier(splitter = \"random\", max_leaf_nodes = 16),\n",
    "                            n_estimators = 500, max_samples = 1.0, bootstrap = True, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.fit(X_train, y_train)\n",
    "accuracy_score(bag_clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=1,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort=False,\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=0.5, n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "                            DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "                            algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ada_clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=42, splitter='best')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=42, splitter='best')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = y - tree_reg1.predict(X)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg2.fit(X, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=42, splitter='best')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3 = y2 - tree_reg2.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
    "tree_reg3.fit(X, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[0.8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75026781])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
